
---------PAGE 1--------


[TITLE] DOCLAYOUT-YOLO: ENHANCING DOCUMENT LAYOUT ANALYSIS THROUGH DIVERSE SYNTHETIC DATA AND GLOBAL-TO-LOCAL ADAPTIVE PERCEPTION


[PLAIN_TEXT] Zhiyuan Zhao; Hengrui Kang; Bin Wang, Conghui He ' Shanghai Artificial Intelligence Laboratory

[TITLE] ABSTRACT


[PLAIN_TEXT] Document Layout Analysis is crucial for real-world document understanding systems, but it encounters a challenging trade-off between speed and accuracy: multimodal methods leveraging both text and visual features achieve higher accuracy but suffer from significant latency, whereas unimodal methods relying solely on visual features offer faster processing speeds at the expense of accuracy. To address this dilemma, we introduce DocLayout-YOLO, a novel approach that enhances accuracy while maintaining speed advantages through document-specific optimizations in both pre-training and model design. For robust document pretraining, we introduce the Mesh-candidate BestFit algorithm, which frames document synthesis as a two-dimensional bin packing problem, generating the largescale, diverse DocSynth-300K dataset. Pre-training on the resulting DocSynth300K dataset significantly improves fine-tuning performance across various document types. In terms of model optimization, we propose a Global-to-Local Controllable Receptive Module that is capable of better handling multi-scale variations of document elements. Furthermore, to validate performance across different document types, we introduce a complex and challenging benchmark named DocStructBench. Extensive experiments on downstream datasets demonstrate that DocLayout-YOLO excels in both speed and accuracy. Code, data, and models are available athttps://github.com/opendatalab/DocLayout-â€”YOLO.

[TITLE] 1 INTRODUCTION


[PLAIN_TEXT] With the rapid advancement of large language models and retrieval-augmented generation (RAG) research Ram et al. (2024), the demand for high-quality document content parsing (Wang et al.||2024b) has become increasingly critical. A central step in document parsing is Document Layout Analysis (DLA), which aims to precisely locate different types of regions (text, titles, tables, graphics, etc.) within a document. Over the past few years, DLA algorithms have made significant progress, performing well on common document types. However, when faced with diverse document formats, existing layout analysis algorithms (Huang et al.|/2022; Li et al.|/2022) still struggle with speed and accuracy.
Currently, there are two main approaches to document parsing: multimodal methods that combine visual and textual information, and unimodal methods that rely solely on visual features. Multimodal methods, which typically involve pretraining on document images using unified text-image encoders, generally achieve higher accuracy but are often slower due to the complexity of their architectures. In contrast, unimodal methods, which rely only on visual features, offer faster processing speeds but tend to lack accuracy due to the absence of specialized pretraining and model design for document data. To achieve robust performance on diverse real-world documents while meeting the demands of real-time applications, this paper introduces the DocLayout-YOLO layout detection algorithm. This method leverages the strengths of both multimodal and unimodal approaches to quickly and accurately identify various regions within documents. As illustrated in Figure[I] DocLayout-YOLO matches the speed of the unimodal method YOLOv10 (Wang et al.|{2024a)
